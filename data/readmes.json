{
  "DSCI551_Foundation-of-Data-Management": "# DSCI551_Foundation-of-Data-Management\nDSCI 551 \u2013 Foundations of Data Management: Focused on database design, SQL, data integrity, and performance optimization, emphasizing scalable and efficient data management practices.\n",
  "Olympic_EDA_Tabelau": "# \ud83c\udfc5 Olympics EDA Dashboard (Tableau)\n\n## \ud83d\udcd8 Overview\nThis project presents an **Exploratory Data Analysis (EDA)** of the **Olympic Games dataset**, visualized through an interactive **Tableau dashboard**.  \nIt provides insights into athlete performance, country-level achievements, and host city distributions across multiple Olympic events.\n\nThe goal is to identify **trends, patterns, and correlations** in Olympic history\u2014such as medal distribution, gender participation, and geographic diversity\u2014using clean, structured datasets.\n\n---\n\n## \ud83d\udcc2 Repository Structure\n```\n\u251c\u2500\u2500 city_loc.csv # City location data (latitude, longitude, country)\n\u251c\u2500\u2500 city_loc.xlsx # Excel version of city location data\n\u251c\u2500\u2500 olympics_cleaned_v4.csv # Cleaned dataset for Tableau EDA\n\u251c\u2500\u2500 olympics_cleaned_v4.xlsx # Excel version for data verification\n\u251c\u2500\u2500 Olympics-EDA.twbx # Tableau packaged workbook with visuals and dashboards\n\u2514\u2500\u2500 README.md # Project documentation\n```\n\n\n---\n\n## \ud83e\udde9 Datasets Used\n\n### 1\ufe0f\u20e3 olympics_cleaned_v4.csv\nContains cleaned and preprocessed Olympic event data.\n\n**Key Columns:**\n- `Name` \u2014 Athlete name  \n- `Country` \u2014 Country/region represented  \n- `Sport` \u2014 Type of sport  \n- `Event` \u2014 Specific event participated in  \n- `Year`, `Season`, `City` \u2014 Temporal and location information  \n- `Medal` \u2014 Gold/Silver/Bronze or None  \n\n### 2\ufe0f\u20e3 city_loc.csv\nMaps each **host city** to its **latitude** and **longitude** for geographic visualization in Tableau.  \nUsed for creating **map-based dashboards** (host city distribution, medal trends by geography).\n\n---\n\n## \ud83e\udde0 Insights & Objectives\nThe Tableau dashboard answers key analytical questions:\n\n- \ud83e\udd47 Which countries have dominated the Olympics historically?  \n- \ud83d\udc69\u200d\ud83e\uddb0 How has **female participation** evolved over time?  \n- \ud83c\udf0d What are the most frequent **host countries and cities**?  \n- \ud83c\udfcb\ufe0f Which sports have seen the **highest medal counts**?  \n- \ud83d\udcca How do **seasonal trends (Summer vs Winter)** affect performance and participation?  \n\n---\n\n## \ud83d\udcca Tableau Dashboard Features\n- Dynamic filters by year, country, sport, and medal type  \n- Map visualizations showing host city locations  \n- Trend lines and area charts for athlete participation growth  \n- Country comparison view for medal distribution  \n- Interactive tooltips for detailed data exploration  \n\n**To view the dashboard:**\n1. Open `Olympics-EDA.twbx` in **Tableau Desktop / Tableau Public**.  \n2. Ensure the linked `.csv` or `.xlsx` files are in the same directory.\n\n---\n\n## \u2699\ufe0f Tools & Technologies\n| Tool | Purpose |\n|------|----------|\n| **Tableau Desktop** | Data visualization and dashboard creation |\n| **Microsoft Excel / CSV** | Data preprocessing and validation |\n| **Python (optional)** | For cleaning raw data before Tableau import |\n\n---\n\n## \ud83d\ude80 How to Use\n1. Clone or download this repository.  \n2. Open `Olympics-EDA.twbx` in Tableau.  \n3. If Tableau prompts for missing data sources, link to:\n   - `olympics_cleaned_v4.xlsx`\n   - `city_loc.xlsx`\n4. Explore the dashboards using interactive filters and legends.\n\n---\n\n## \ud83d\udcc8 Key Findings (Based on Tableau Visualizations)\n\n### \ud83c\udf0d **1. Global Olympic Distribution**\n- The map visualization highlights **major host cities** such as *Tokyo, Los Angeles, Moscow, Barcelona,* and *Melbourne*.\n- The **distinct count of participating countries** increased from **12 in 1896** to over **200 by 2016**, showing massive global expansion.\n\n### \ud83c\udfc5 **2. Medal Tally Insights**\n- **USA**, **Russia**, **China**, and **Japan** remain dominant medal winners.  \n- In the **2016 Olympics**, *Australia*, *France*, and *Japan* ranked among the top medal-earning nations.  \n- The country-wise table allows exploration of each nation\u2019s **Gold, Silver, and Bronze** distribution interactively.\n\n### \ud83d\udd70\ufe0f **3. Year-Wise Trends**\n- From **1896 to 2016**, the **number of medals awarded** increased dramatically as more sports were added.  \n- The chart shows consistent Olympic growth with peaks during modern decades.\n\n### \ud83d\udc69\u200d\ud83e\uddb0 **4. Gender Participation**\n- The **Gender Divide** pie chart shows women\u2019s participation rose from **<5% in early 1900s** to **over 45% by 2016**.  \n- Female athletes\u2019 participation began increasing sharply after 1968 and continues to approach parity.\n\n### \ud83d\udcca **5. Athlete Demographics**\n- **Age Histogram** shows most athletes are between **20\u201330 years**, confirming prime performance age.\n- **Scatterplot of Height vs Weight** indicates clear clustering by gender \u2014 taller/heavier athletes (men) versus lighter clusters (women).\n\n### \ud83c\udfcb\ufe0f **6. Country-Specific Deep Dives**\n- Filters for **Country** (e.g., USA) show:\n  - **Swimming** and **Athletics** lead the medal counts.\n  - Top athletes like *Michael Phelps* and *Simone Biles* dominate specific sports.\n  - Visualization enables tracking of **top sports** and **top athletes** by country.\n\n---\n\n## \ud83d\udcdc Credits\n- **Data Source:** Kaggle\u2019s *Olympic History Dataset* (1896\u20132020).  \n- **Developed by:** *Khushi Patel*  \n  - \ud83c\udf93 *M.S. Applied Data Science, University of Southern California*  \n  - \ud83d\udcbb *Specializing in Data Visualization, Machine Learning, and Analytics*  \n\n---\n\n",
  "Movie-Recommendation": "# \ud83c\udfac Movie Recommendation System\n\nThis project is a content-based movie recommendation system built with **Python**, **Streamlit**, and **TMDB API**.  \nIt suggests similar movies based on a selected title and displays their posters.\n\n---\n\n## \ud83d\ude80 Features\n- Select any movie from the dataset.\n- Get **10 movie recommendations** instantly.\n- Displays movie posters fetched from TMDB API.\n- Simple and interactive **Streamlit web app**.\n\n---\n\n## \ud83d\udee0\ufe0f Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/Khushipatel27/movie-recommendation.git\n   cd movie-recommender\n   ```\n\n2. Create and activate a virtual environment:\n```\npython -m venv myenv\nsource myenv/bin/activate #for mac\nmyenv\\Scripts\\activate #for windows\n```\n\n3. Install dependencies:\n```\npip install -r requirements.txt\n```\n\n4. Make sure you have the following files in your project:\n- movie_dict.pkl\n- similarity.pkl\n\n\u25b6\ufe0f Running the App\n\nRun the following command:\n```\nstreamlit run app.py\n```\n\n## \ud83d\udcf8 Demo Screenshots\n<img width=\"1869\" height=\"1854\" alt=\"Screenshot 2025-09-09 000534\" src=\"https://github.com/user-attachments/assets/b3057abd-8e24-4d0c-8afa-2449fc4f8928\" />\n<img width=\"1565\" height=\"1697\" alt=\"Screenshot 2025-09-09 000514\" src=\"https://github.com/user-attachments/assets/3d1c138d-7b2f-4b32-abd3-3503279078b4\" />\n\n## \ud83d\udcc2 Output Example\n\nWhen you select a movie, the system will display 10 recommendations in 2 rows with posters:\nMovie Selected: Avatar\n\nRecommendations:\n- John Carter\n- Guardians of the Galaxy\n- The Avengers\n- Thor\n- Star Trek\n- Green Lantern\n- Man of Steel\n- Prometheus\n\n## \u26a1 Tech Stack\n- Python\n- Streamlit\n- Pandas\n- Pickle\n- Requests (TMDB API)\n\n## \ud83d\ude4c Acknowledgements\nTMDB API for movie posters and metadata.\n\n\n\n",
  "Face-Recognition-Attendance-System": "# Face Recognition Attendance System\n\nAn advanced face recognition-based attendance system built with OpenCV, face_recognition, and SVM classifier.  \nThe system detects and recognizes faces in real-time, tracks multiple people using Deep SORT, and marks attendance automatically into a CSV file.\n\n## Features\n- Automatic face detection and recognition\n- Real-time face tracking using Deep SORT\n- SVM classifier with hyperparameter tuning\n- Data augmentation and preprocessing for robust training\n- Stores attendance with Name, Date, and Time in CSV\n- Supports multiple people in the dataset\n- Saves and loads trained models (.pkl file)\n\n## Project Structure\n```\nFaceRecognitionAttendance/\n\u2502\u2500\u2500 dataset/                 # Folder containing training images\n\u2502   \u251c\u2500\u2500 John/                # Each person has a separate folder\n\u2502   \u2502   \u251c\u2500\u2500 img1.jpg\n\u2502   \u2502   \u251c\u2500\u2500 img2.jpg\n\u2502   \u2514\u2500\u2500 Mary/\n\u2502       \u251c\u2500\u2500 img1.jpg\n\u2502       \u251c\u2500\u2500 img2.jpg\n\u2502\n\u2502\u2500\u2500 index.ipynb              # Script to train the face recognition model and Main attendance system script\n\u2502\u2500\u2500 trained_face_model.pkl   # Saved trained model\n\u2502\u2500\u2500 attendance_YYYY-MM-DD.csv # Generated attendance file\n\u2502\u2500\u2500 README.md                # Project documentation\n```\n\n## Installation\n1. Clone this repository:\n   ```\n   git clone https://github.com/Khushipatel27/face-recognition-attendance.git\n   cd face-recognition-attendance\n   ```\n\n2. Install dependencies:\n   ```\n   pip install -r requirements.txt\n   ```\n\n## Dataset Setup\n1. Create a dataset/ folder in the project directory.\n2. Inside dataset/, create one subfolder per person (e.g., dataset/John/, dataset/Mary/).\n3. Add at least 3\u20135 clear face images per person.\n   Supported formats: .jpg, .jpeg, .png, .bmp\nExample:\n```\ndataset/\n\u251c\u2500\u2500 John/\n\u2502   \u251c\u2500\u2500 1.jpg\n\u2502   \u251c\u2500\u2500 2.jpg\n\u251c\u2500\u2500 Mary/\n\u2502   \u251c\u2500\u2500 1.jpg\n\u2502   \u251c\u2500\u2500 2.jpg\n```\n\n## Training and Testing the Model\nOpen and run the Jupyter Notebook:\n   jupyter notebook index.ipynb\n\nThis notebook includes:\n- Dataset validation\n- Image preprocessing and augmentation\n- Training an SVM classifier with hyperparameter tuning\n- Testing the model on validation data\n- Saving the trained model as trained_face_model.pkl\n\n## Running the Attendance System\nOnce the model is trained, open the Jupyter Notebook:\n   jupyter notebook index.ipynb\n\n- Run the second cell in the notebook to start the attendance system.\n- The system will open your webcam.\n- Detected and recognized faces will appear with bounding boxes.\n- Attendance will be logged in attendance_YYYY-MM-DD_HH-MM-SS.csv\n- Press q to quit the application.\n\n## Output Example\nAttendance file (attendance_2025-09-09_10-30-00.csv):\n\n\n| Name   | Date        | Time      |\n|--------|-------------|-----------|\n| John   | 2025-09-09  | 10:31:05  |\n| Mary   | 2025-09-09  | 10:32:47  |\n\n\n## Demo Screenshot\nBelow is an example screenshot of the system in action:\n\n<img width=\"1600\" height=\"1262\" alt=\"Screenshot 2025-09-09 122747\" src=\"https://github.com/user-attachments/assets/24220bbc-267b-4c7a-97bd-b197bc1b62e2\" />\n<img width=\"1587\" height=\"1196\" alt=\"Screenshot 2025-09-09 123149\" src=\"https://github.com/user-attachments/assets/51731fc8-5242-40e5-b313-f7d8c29b1507\" />\n<img width=\"1603\" height=\"1191\" alt=\"Screenshot 2025-09-09 123218\" src=\"https://github.com/user-attachments/assets/f490905d-1f7a-4b30-9d9b-55ae7e22a508\" />\n<img width=\"1171\" height=\"595\" alt=\"Screenshot 2025-09-09 142815\" src=\"https://github.com/user-attachments/assets/7bd6812d-db9c-40fa-889d-f9b655e559a3\" />\n\n## Future Improvements\n- Add a GUI for better usability\n- Integrate with a database (MySQL / MongoDB)\n- Deploy on cloud for remote attendance marking\n- Mobile app integration for teachers/students\n\n\n\n\n",
  "Comprehensive-Sales-EDA-Dashboard": "# \ud83d\udcca Comprehensive Sales EDA Dashboard\n\nAn interactive Streamlit dashboard for performing **exploratory data analysis** on sales data using the Superstore dataset. Gain actionable insights through detailed statistical summaries, visualizations, and key business metrics.\n\n## \ud83c\udf1f Features\n\n### \ud83d\udccb Dataset Overview\n- Full dataset information and statistical summary\n- Preview and explore sample data with dark-themed tables\n- Identify missing values, duplicates, and basic data integrity checks\n- Key metric summaries (Total Sales, Total Profit, Average Profit Margin, etc.)\n\n### \ud83d\udcca Yearly and Category Analysis\n- Year-over-year sales and profit comparisons\n- Monthly and quarterly trend visualizations\n- Product category and sub-category performance insights\n- Regional and segment-wise analysis\n\n### \ud83d\udd0d Advanced Analytics\n- Correlation and distribution analysis\n- Customer segmentation insights\n- Quantity vs. Profit vs. Discount visualizations\n- Heatmaps for metric relationships\n- Seasonal and trend pattern identification\n\n## \ud83d\ude80 Quick Start\n\n### Prerequisites\n\n```bash\npip install streamlit pandas matplotlib seaborn plotly\n```\n\n## Installation\n\n1. Clone the repository\n   ```\n   git clone https://github.com/Khushipatel27/sales-eda-dashboard.git\n   cd sales-eda-dashboard\n   ```\n2. Install dependencies\n   ```\n   pip install -r requirements.txt\n   ```\n3. Run the dashboard\n   ```\n   streamlit run dashboard.py\n   ```\n4. Access the application\n- Open your browser and go to http://localhost:8501\n\n## Project Structure\n```\nsales-eda-dashboard/\n\u2502\n\u251c\u2500\u2500 dashboard.py                 # Main Streamlit application\n\u251c\u2500\u2500 index.ipynb                  # Jupyter notebook for detailed analysis\n\u251c\u2500\u2500 Dataset_Superstore.csv       # Superstore dataset\n\u251c\u2500\u2500 requirements.txt             # Python dependencies\n\u251c\u2500\u2500 README.md                    # Project documentation\n\u2514\u2500\u2500 screenshots/                 # Sample visualizations\n    \u251c\u2500\u2500 overview.png\n    \u251c\u2500\u2500 yearly_analysis.png\n    \u2514\u2500\u2500 correlation_heatmap.png\n```\n\n## \ud83d\udcca Dataset Information\n\nThe Superstore dataset contains **9,994 records** with columns such as:\n\n| Column        | Description                                   |\n|---------------|-----------------------------------------------|\n| Order Info    | Row ID, Order ID, Order Date, Ship Date, Ship Mode |\n| Customer Info | Customer ID, Customer Name, Segment          |\n| Location      | Country, City, State, Postal Code, Region    |\n| Product Info  | Product ID, Category, Sub-Category, Product Name |\n| Metrics       | Sales, Quantity, Discount, Profit            |\n\n## \ud83c\udf9b\ufe0f Dashboard Screenshots\n\n\n<img width=\"3839\" height=\"1961\" alt=\"Screenshot 2025-09-06 144657\" src=\"https://github.com/user-attachments/assets/332df41d-9cbe-4785-bf3b-626ee4f24edc\" />\n<img width=\"3714\" height=\"1971\" alt=\"Screenshot 2025-09-06 144824\" src=\"https://github.com/user-attachments/assets/c2537761-389d-474c-bff8-95aecd30a456\" />\n<img width=\"3066\" height=\"1454\" alt=\"Screenshot 2025-09-06 144834\" src=\"https://github.com/user-attachments/assets/c104aa6c-b9ba-43d2-9fb9-55530e1ce3e3\" />\n<img width=\"3062\" height=\"1821\" alt=\"Screenshot 2025-09-06 144855\" src=\"https://github.com/user-attachments/assets/20dbfea7-584f-4e98-845e-654bd41d0e43\" />\n<img width=\"3049\" height=\"1900\" alt=\"Screenshot 2025-09-06 144921\" src=\"https://github.com/user-attachments/assets/2222ef3d-1516-4049-bf6a-16e80a1a1baf\" />\n<img width=\"3088\" height=\"1890\" alt=\"Screenshot 2025-09-06 145002\" src=\"https://github.com/user-attachments/assets/d5a11bd9-a4cc-4cfb-8033-6cdaf9ae539e\" />\n<img width=\"3134\" height=\"1855\" alt=\"Screenshot 2025-09-06 145015\" src=\"https://github.com/user-attachments/assets/8ec50a70-0a15-4187-a1ea-be85ea7bd9b8\" />\n<img width=\"2947\" height=\"1581\" alt=\"Screenshot 2025-09-06 145046\" src=\"https://github.com/user-attachments/assets/49a3d30e-a2bf-48ab-9804-2ee5cb2ea95c\" />\n<img width=\"2385\" height=\"1446\" alt=\"Screenshot 2025-09-06 145111\" src=\"https://github.com/user-attachments/assets/1dbdd7e8-36bb-40e0-955c-a5dba3298742\" />\n<img width=\"2810\" height=\"1442\" alt=\"Screenshot 2025-09-06 145147\" src=\"https://github.com/user-attachments/assets/00dcafe7-6997-4f34-903b-54adbf884159\" />\n<img width=\"2661\" height=\"1503\" alt=\"Screenshot 2025-09-06 145154\" src=\"https://github.com/user-attachments/assets/c70626c4-fbc4-4f9e-96ca-102220329a54\" />\n<img width=\"623\" height=\"1647\" alt=\"Screenshot 2025-09-06 145205\" src=\"https://github.com/user-attachments/assets/f19b468a-bc79-463d-b36e-8e951c6db7d7\" />\n\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch (git checkout -b feature/NewFeature)\n3. Commit your changes (git commit -m 'Add NewFeature')\n4. Push to the branch (git push origin feature/NewFeature)\n5. Open a Pull Request\n\n## Run the dashboard\n```\nstreamlit run app1.py\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
  "Car-Crash-Detection": "# \ud83d\ude97 Car Crash Detection & Risk Analysis System\n\nA real-time Computer Vision system that detects car crashes, estimates vehicle speed, analyzes crash risk levels, sends emergency SOS alerts, and generates comprehensive reports. The system utilizes advanced object detection techniques with YOLOv8, specifically leveraging both YOLOv8n and YOLOv8m models. Depending on the scenario, weights from either model are used to balance speed and accuracy \u2014 with YOLOv8n optimized for faster inference and YOLOv8m for improved detection precision. Through this combined approach, the system achieves an overall detection accuracy of approximately 60%, providing dynamic visual feedback using bounding box color changes based on risk probability.\n\n---\n\n## \ud83e\udde0 Key Features\n\n- \ud83d\udd0d **Car Crash Detection**  \n  Detects collisions in real-time using YOLO-based object detection on video feeds or uploaded videos.\n\n- \ud83d\udee3\ufe0f **Vehicle Speed Estimation**  \n  Estimates the speed of detected vehicles frame-by-frame.\n\n- \u26a0\ufe0f **Crash Risk Analysis**  \n  Calculates the probability of a crash occurring and updates bounding box colors:\n  - \ud83d\udfe9 **Green** \u2013 Low Risk  \n  - \ud83d\udfe8 **Yellow** \u2013 Moderate Risk  \n  - \ud83d\udfe5 **Red** \u2013 High Risk  \n\n- \ud83e\udde0 **Advanced Crash Risk Assessment**  \n  **Proactive Monitoring Before Accidents Occur:**\n  - **Speed Estimation:** Calculated using real-world calibration and frame displacement analysis.  \n  - **Risk Factors Considered:**  \n    - Vehicle speed and acceleration  \n    - Proximity to other vehicles  \n    - Erratic movements and sudden braking  \n  - **Visual Risk Indicators:** Bounding boxes colored based on risk levels (%) for intuitive visual feedback.\n\n- \ud83c\udd98 **SOS Emergency Alert System**  \n  Automatically sends SOS alerts with crash data (e.g., time, location, risk level) to emergency contacts when a high-risk crash is detected.\n\n- \ud83d\udcca **Comprehensive Reporting System**  \n  **Automated Report Generation (CSV Format):**\n  - Unique vehicle tracking with consistent IDs  \n  - Recorded maximum speed per vehicle  \n  - Estimated crash probability percentages  \n  - Key risk factor annotations  \n  - Accident timestamps and location logs\n\n- \ud83c\udfa5 **Video Input Support**  \n  Accepts video files or live camera feeds for analysis.\n\n---\n\ud83d\uddbc\ufe0f Screenshots & Demo\nCar Crash Detection in Action\nHere is a screenshot of the car crash detection in action:\n\n![Image With accident](Images/image-1.png)\n![Image Wihtout accident](Images/image-2.png)\n![Report](Images/image.png)\n![SOS Message](Images/1.jpg)\n![SOS Email](Images/email.jpg)\n\n## \ud83d\udee0\ufe0f Tech Stack\n\n- **YOLOv8** \u2013 Object detection for car and crash detection  \n- **OpenCV** \u2013 Video processing and visualization  \n- **Python** \u2013 Backend logic and report generation  \n- **Pandas** \u2013 Data handling and analytics  \n- **Matplotlib / Seaborn** \u2013 Graphs  \n- **SMTP / Twilio API** \u2013 For SOS alerts via email/SMS  \n\n---\n## \ud83d\udcc1 Project Structure\n\n```bash\n\u251c\u2500\u2500 Runs/                          # YOLO training outputs\n\u251c\u2500\u2500 MEDIUM/                        # YOLOV8M trained output\n\u251c\u2500\u2500 NONO/                          # YOLOV8N trained output\n\u251c\u2500\u2500 train/                         # YOLOv8 training notebooks\n\u2502   \u251c\u2500\u2500 yolov8m_train.ipynb        \n\u2502   \u251c\u2500\u2500 yolov8m_2_train.ipynb      \n\u2502   \u2514\u2500\u2500 yolov8n_train.IPYNB        \n\u251c\u2500\u2500 video_final/                   # Sample crash videos\n\u2502   \u251c\u2500\u2500 Crash_1.mp4\n\u2502   \u251c\u2500\u2500 Crash_2.mp4\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 detection_report.csv           # Auto-generated report\n\u251c\u2500\u2500 output_crash_detection.mp4     # Final processed video with bounding boxes\n\u251c\u2500\u2500 main.ipynb                     # Main code for detection and analysis\n\u251c\u2500\u2500 .gitignore                     # Git ignore config\n\u2514\u2500\u2500 requirements.txt               # Dependencies \n\nHow to Run\n1. Clone the Repository\ngit clone https://github.com/khushipatel27/car-crash-detection.git\ncd car-crash-detection\n\n2. Install Dependencies Make sure you have Python installed. Then run:\npip install -r requirements.txt\n\n3.Run the Main Script Launch the detection system:\njupyter notebook main.ipynb\n\n4. Dataset Link\nhttps://drive.google.com/drive/folders/1Posjr0TfdnQ7f6Zy8hWgIrHtvBZWzWEc?usp=sharing\n\n",
  "Electricity-Demand-Forecasting-with-LSTM-SARSA": "# \u26a1 Electricity Demand Forecasting with LSTM & SARSA\n\nThis project explores hybrid approaches for forecasting electricity demand using:\n- Deep Learning (LSTM) to capture sequential patterns in time-series data  \n- Reinforcement Learning (SARSA) to optimize decision-making policies based on forecasts  \n\n---\n\n## \ud83d\udccc Overview / Motivation\nAccurate electricity demand forecasting is crucial for:\n- Ensuring grid stability  \n- Reducing costs from over/under-supply  \n- Enabling better renewable energy integration  \n\nWhile LSTM provides reliable short-term forecasts, SARSA introduces an adaptive reinforcement learning agent that learns how to optimize energy management strategies from demand predictions. Together, they provide both prediction and decision optimization.\n\n---\n\n## \ud83d\udee0\ufe0f Tech Stack / Dependencies\n- Python 3.8+\n- Libraries:\n  - `pandas`, `numpy` \u2192 Data preprocessing\n  - `matplotlib`, `seaborn` \u2192 Visualization\n  - `scikit-learn` \u2192 Scaling, splitting data\n  - `keras` / `tensorflow` \u2192 Deep Learning (LSTM)\n  - Custom implementation of SARSA algorithm  \n\nYou can install dependencies via:\npip install -r requirements.txt\n\n## Dataset\nThe dataset used (continuous dataset.csv) contains:\n  - T2M_toc \u2192 Temperature (Tocumen city)\n  - QV2M_toc \u2192 Humidity\n  - TQL_toc \u2192 Total liquid water\n  - W2M_toc \u2192 Wind speed\n  - T2M_san \u2192 Temperature (Santiago city)\n  - nat_demand \u2192 Target variable: National electricity demand\n\n\n## Project Structure\n- DL.ipynb                 # Jupyter Notebook (LSTM + SARSA implementation)\n- continuous dataset.csv    # Dataset (not included in repo)\n- requirements.txt          # Python dependencies\n- README.md                 # Project documentation\n\n## How to Run\n1. Clone the repository\n  - git clone https://github.com/Khushipatel27/Electricity-Demand-Forecasting-with-LSTM-SARSA.git\n  - cd electricity-demand-lstm-sarsa\n\n2. Install dependencies\n  - pip install -r requirements.txt\n\n3. Run the notebook\n  - jupyter notebook DL.ipynb\n\nFollow the notebook to:\n  1.Preprocess the dataset\n  2.Train and evaluate the LSTM model\n  3.Train and test the SARSA agent\n\n## Results\n- Forecasts future electricity demand from historical weather & demand data\n- Visualization of actual vs. predicted demand\n\n<img width=\"2800\" height=\"1487\" alt=\"image\" src=\"https://github.com/user-attachments/assets/f8d4b769-f000-4733-927e-980137c398e9\" />\n\n\n<img width=\"2794\" height=\"1398\" alt=\"image\" src=\"https://github.com/user-attachments/assets/151cb3c2-6479-47d9-8a2b-116c661000a4\" />\n\n\n<img width=\"2798\" height=\"1194\" alt=\"image\" src=\"https://github.com/user-attachments/assets/1d03a248-7dcc-43c9-ad7d-cbb30e43a123\" />\n\n## Future Work\n  - Hyperparameter tuning (LSTM layers, SARSA learning rate, epsilon decay)\n  - Compare with other RL algorithms (Q-learning, DQN)\n  - Include seasonal and holiday effects\n  - Deploy as a Flask/Django API or interactive dashboard\n\n## Contributing\nContributions are welcome!\nIf you'd like to improve this project:\n  1. Fork the repo\n  2. Create your feature branch (git checkout -b feature-name)\n  3. Commit your changes (git commit -m 'Add feature')\n  4. Push to the branch (git push origin feature-name)\n  5. Open a Pull Request\n\n\n  \n\n\n\n\n"
}